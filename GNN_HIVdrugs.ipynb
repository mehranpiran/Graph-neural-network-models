{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "43b2da8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15d90c770>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import numpy as np \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bf862081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   smiles activity  HIV_active\n",
       "0      CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...       CI           0\n",
       "1      C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...       CI           0\n",
       "2                       CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21       CI           0\n",
       "3        Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1       CI           0\n",
       "4                                 O=S(=O)(O)CCS(=O)(=O)O       CI           0\n",
       "...                                                  ...      ...         ...\n",
       "41122  CCC1CCC2c3c([nH]c4ccc(C)cc34)C3C(=O)N(N(C)C)C(...       CI           0\n",
       "41123  Cc1ccc2[nH]c3c(c2c1)C1CCC(C(C)(C)C)CC1C1C(=O)N...       CI           0\n",
       "41124  Cc1ccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)C...       CI           0\n",
       "41125  Cc1cccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)...       CI           0\n",
       "41126  CCCCCC=C(c1cc(Cl)c(OC)c(-c2nc(C)no2)c1)c1cc(Cl...       CI           0\n",
       "\n",
       "[41127 rows x 3 columns]>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Path = \"/Users/mpir0002/Downloads/gnn-project/data/raw/HIV.csv\"\n",
    "data = pd.read_csv(Data_Path)\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a3c20531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        root = Where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (processed data). \n",
    "        \"\"\"\n",
    "        self.test = test\n",
    "        self.filename = filename\n",
    "        super(MoleculeDataset, self).__init__(root, transform, pre_transform)\n",
    "        \n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        return self.filename\n",
    "\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
    "\n",
    "        if self.test:\n",
    "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
    "        else:\n",
    "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0])\n",
    "        for index, mol in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
    "            mol_obj = Chem.MolFromSmiles(mol[\"smiles\"])\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(mol_obj)\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(mol_obj)\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(mol_obj)\n",
    "            # Get labels info\n",
    "            label = self._get_labels(mol[\"HIV_active\"])\n",
    "\n",
    "            # Create data object\n",
    "            data = Data(x=node_feats, \n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_feats,\n",
    "                        y=label,\n",
    "                        smiles=mol[\"smiles\"]\n",
    "                        ) \n",
    "            if self.test:\n",
    "                torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_test_{index}.pt'))\n",
    "            else:\n",
    "                torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_{index}.pt'))\n",
    "\n",
    "    def _get_node_features(self, mol):\n",
    "        \n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of Nodes, Node Feature size]\n",
    "        \"\"\"\n",
    "        \n",
    "        all_node_feats = []\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            node_feats = []\n",
    "            # Feature 1: Atomic number        \n",
    "            node_feats.append(atom.GetAtomicNum())\n",
    "            # Feature 2: Atom degree\n",
    "            node_feats.append(atom.GetDegree())\n",
    "            # Feature 3: Formal charge\n",
    "            node_feats.append(atom.GetFormalCharge())\n",
    "            # Feature 4: Hybridization\n",
    "            node_feats.append(atom.GetHybridization())\n",
    "            # Feature 5: Aromaticity\n",
    "            node_feats.append(atom.GetIsAromatic())\n",
    "            # Feature 6: Total Num Hs\n",
    "            node_feats.append(atom.GetTotalNumHs())\n",
    "            # Feature 7: Radical Electrons\n",
    "            node_feats.append(atom.GetNumRadicalElectrons())\n",
    "            # Feature 8: In Ring\n",
    "            node_feats.append(atom.IsInRing())\n",
    "            # Feature 9: Chirality\n",
    "            node_feats.append(atom.GetChiralTag())\n",
    "\n",
    "            # Append node features to matrix\n",
    "            all_node_feats.append(node_feats)\n",
    "\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_edge_features(self, mol):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of edges, Edge Feature size]\n",
    "        \"\"\"\n",
    "        all_edge_feats = []\n",
    "\n",
    "        for bond in mol.GetBonds():\n",
    "            edge_feats = []\n",
    "            # Feature 1: Bond type (as double)\n",
    "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
    "            # Feature 2: Rings\n",
    "            edge_feats.append(bond.IsInRing())\n",
    "            # Append node features to matrix (twice, per direction)\n",
    "            all_edge_feats += [edge_feats, edge_feats]\n",
    "\n",
    "        all_edge_feats = np.asarray(all_edge_feats)\n",
    "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_adjacency_info(self, mol):\n",
    "        \"\"\"\n",
    "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
    "        but we want to be sure that the order of the indices\n",
    "        matches the order of the edge features\n",
    "        \"\"\"\n",
    "        edge_indices = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_indices += [[i, j], [j, i]]\n",
    "\n",
    "        edge_indices = torch.tensor(edge_indices)\n",
    "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "        return edge_indices\n",
    "\n",
    "    def _get_labels(self, label):\n",
    "        label = np.asarray([label])\n",
    "        return torch.tensor(label, dtype=torch.int64)\n",
    "\n",
    "    def len(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
    "            - Is not needed for PyG's InMemoryDataset\n",
    "        \"\"\"\n",
    "        if self.test:\n",
    "            data = torch.load(os.path.join(self.processed_dir, \n",
    "                                 f'data_test_{idx}.pt'))\n",
    "        else:\n",
    "            data = torch.load(os.path.join(self.processed_dir, \n",
    "                                 f'data_{idx}.pt'))   \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "061b05f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████▊               | 35060/41127 [00:24<00:04, 1331.33it/s][10:59:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:59:12] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 41127/41127 [00:29<00:00, 1394.25it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = MoleculeDataset(root='data/' , filename=\"HIV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "048ae1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoleculeDataset(41127)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a1228a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1],\n",
      "        [ 1,  0],\n",
      "        [ 1,  2],\n",
      "        [ 2,  1],\n",
      "        [ 2,  3],\n",
      "        [ 3,  2],\n",
      "        [ 3,  4],\n",
      "        [ 4,  3],\n",
      "        [ 4,  5],\n",
      "        [ 5,  4],\n",
      "        [ 4,  6],\n",
      "        [ 6,  4],\n",
      "        [ 6,  7],\n",
      "        [ 7,  6],\n",
      "        [ 7,  8],\n",
      "        [ 8,  7],\n",
      "        [ 8,  9],\n",
      "        [ 9,  8],\n",
      "        [ 9, 10],\n",
      "        [10,  9],\n",
      "        [10, 11],\n",
      "        [11, 10],\n",
      "        [11, 12],\n",
      "        [12, 11],\n",
      "        [12, 13],\n",
      "        [13, 12],\n",
      "        [13, 14],\n",
      "        [14, 13],\n",
      "        [ 7, 15],\n",
      "        [15,  7],\n",
      "        [15, 16],\n",
      "        [16, 15],\n",
      "        [16, 17],\n",
      "        [17, 16],\n",
      "        [17, 18],\n",
      "        [18, 17],\n",
      "        [18, 19],\n",
      "        [19, 18],\n",
      "        [18, 20],\n",
      "        [20, 18],\n",
      "        [17, 21],\n",
      "        [21, 17],\n",
      "        [21, 22],\n",
      "        [22, 21],\n",
      "        [21,  1],\n",
      "        [ 1, 21],\n",
      "        [16,  3],\n",
      "        [ 3, 16],\n",
      "        [13,  8],\n",
      "        [ 8, 13]])\n",
      "tensor([[ 6.,  1.,  0.,  4.,  0.,  3.,  0.,  0.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 6.,  2.,  0.,  3.,  1.,  1.,  0.,  1.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 8.,  1.,  0.,  3.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 6.,  2.,  0.,  3.,  1.,  1.,  0.,  1.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 6.,  2.,  0.,  3.,  1.,  1.,  0.,  1.,  0.],\n",
      "        [ 6.,  2.,  0.,  3.,  1.,  1.,  0.,  1.,  0.],\n",
      "        [ 6.,  2.,  0.,  3.,  1.,  1.,  0.,  1.,  0.],\n",
      "        [ 6.,  2.,  0.,  3.,  1.,  1.,  0.,  1.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [17.,  1.,  0.,  4.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 8.,  2.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 8.,  1.,  0.,  3.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 8.,  1.,  0.,  3.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 6.,  3.,  0.,  3.,  1.,  0.,  0.,  1.,  0.],\n",
      "        [ 6.,  1.,  0.,  4.,  0.,  3.,  0.,  0.,  0.]])\n",
      "tensor([[1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [2.0000, 0.0000],\n",
      "        [2.0000, 0.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [2.0000, 0.0000],\n",
      "        [2.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.0000, 0.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000],\n",
      "        [1.5000, 1.0000]])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0].edge_index.t())\n",
    "print(dataset[0].x)\n",
    "print(dataset[0].edge_attr)\n",
    "print(dataset[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ca19030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41127\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0f3da820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d53bb4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(data.is_directed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b5fe48c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(data.num_nodes)\n",
    "print(data.num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "45ef17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ed8e4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Configuring models architecture ###############\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        num_classes = 2\n",
    "        embedding_size = 1024\n",
    "        \n",
    "        # GNN layers\n",
    "        self.conv1 = GATConv(feature_size , embedding_size , heads=3 , dropout = 0.3)\n",
    "        self.head_transform1 = Linear(embedding_size*3 , embedding_size)\n",
    "        self.pool1 = TopKPooling(embedding_size , ratio = 0.8)\n",
    "        self.conv2 = GATConv(embedding_size , embedding_size , heads=3 , dropout = 0.3)\n",
    "        self.head_transform2 = Linear(embedding_size*3 , embedding_size)\n",
    "        self.pool2 = TopKPooling(embedding_size , ratio = 0.5)\n",
    "        self.conv3 = GATConv(embedding_size , embedding_size , heads=3 , dropout = 0.3)\n",
    "        self.head_transform3 = Linear(embedding_size*3 , embedding_size)\n",
    "        self.pool3 = TopKPooling(embedding_size , ratio = 0.3)\n",
    "        \n",
    "        # Linear layers\n",
    "        self.linear1 = Linear(embedding_size*2 , 1024)\n",
    "        self.linear2 = Linear(1024 , num_classes)\n",
    "        \n",
    "    def forward(self , x , edge_index , batch_index):\n",
    "        \n",
    "        x = self.conv1(x , edge_index)\n",
    "        x = self.head_transform1(x)\n",
    "        x , edge_index , edge_attr , batch_index , _ , _ = self.pool1(x , edge_index, None, batch_index)\n",
    "        x1 = torch.cat([gmp(x , batch_index) , gap(x , batch_index)] , dim = 1)\n",
    "        \n",
    "        x = self.conv2(x , edge_index)\n",
    "        x = self.head_transform2(x)\n",
    "        x , edge_index , edge_attr , batch_index , _ , _ = self.pool2(x , edge_index, None, batch_index)\n",
    "        x2 = torch.cat([gmp(x , batch_index) , gap(x , batch_index)] , dim = 1)\n",
    "        \n",
    "        x = self.conv3(x , edge_index)\n",
    "        x = self.head_transform3(x)\n",
    "        x , edge_index , edge_attr , batch_index , _ , _ = self.pool3(x , edge_index, None, batch_index)\n",
    "        x3 = torch.cat([gmp(x , batch_index) , gap(x , batch_index)] , dim = 1)\n",
    "        \n",
    "        x = x1 + x2 + x3\n",
    "        \n",
    "        x = self.linear1(x).relu()\n",
    "        x = F.dropout(x , p = 0.5 , training = self.training)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8cf1f965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41127"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e540f508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 300\n",
      "Number of test graphs: 99\n"
     ]
    }
   ],
   "source": [
    "### Spliting data into train and test\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# Once it's shuffled, we slice the data to split\n",
    "train_dataset = dataset[0:300]\n",
    "test_dataset = dataset[301:400]\n",
    "\n",
    "# Take a look at the training versus test graphs\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e0092b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv1): GATConv(9, 1024, heads=3)\n",
       "  (head_transform1): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "  (pool1): TopKPooling(1024, ratio=0.8, multiplier=1.0)\n",
       "  (conv2): GATConv(1024, 1024, heads=3)\n",
       "  (head_transform2): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "  (pool2): TopKPooling(1024, ratio=0.5, multiplier=1.0)\n",
       "  (conv3): GATConv(1024, 1024, heads=3)\n",
       "  (head_transform3): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "  (pool3): TopKPooling(1024, ratio=0.3, multiplier=1.0)\n",
       "  (linear1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Training Data ###############\n",
    "\n",
    "model = GNN(feature_size=train_dataset[0].x.shape[1])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "731c88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([1,10] , dtype = torch.float32)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = 0.1 , momentum = 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer , gamma = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "af507bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset , batch_size=40 , shuffle=True)\n",
    "test_loader = DataLoader(test_dataset , batch_size = 40 , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dc026f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    print(f\"\\n Confusion matrix: \\n {confusion_matrix(y_pred, y_true)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e9919952",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Model evaluation ##################\n",
    "\n",
    "def train(epoch , model, train_loader, loss_fn):\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    \n",
    "    for _, batch in enumerate(tqdm(train_loader)):\n",
    "         \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(batch.x.float(), \n",
    "                                batch.edge_index, \n",
    "                                batch.batch) \n",
    "        # Calculating the loss and gradients\n",
    "        loss = torch.sqrt(loss_fn(pred, batch.y))\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        \n",
    "        all_preds.append(np.argmax(pred.detach().cpu().numpy(), axis=1))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return running_loss\n",
    "\n",
    "def test(epoch, model, test_loader, loss_fn):\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    \n",
    "    for batch in test_loader:\n",
    "        pred = model(batch.x.float(), \n",
    "                        batch.edge_attr.float(),\n",
    "                        batch.batch) \n",
    "        loss = torch.sqrt(loss_fn(pred, batch.y))\n",
    "\n",
    "         # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds = np.concatenate(all_preds).ravel()\n",
    "        all_labels = np.concatenate(all_labels).ravel()\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    print(all_preds[:10])\n",
    "    print(all_labels[:10])\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    #log_conf_matrix(all_preds, all_labels, epoch)\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3b06a92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoleculeDataset(300)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a81a64df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:18<00:00, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      " [[288  12]\n",
      " [  0   0]]\n",
      "F1 Score: 0.0\n",
      "Accuracy: 0.96\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/mpir0002/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(epoch= 1 , model=model , train_loader=train_dataset , loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "333bc44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: nan\n",
      "Epoch 2, Loss: nan\n",
      "Epoch 3, Loss: nan\n",
      "Epoch 4, Loss: nan\n",
      "Epoch 5, Loss: nan\n",
      "Epoch 6, Loss: nan\n",
      "Epoch 7, Loss: nan\n",
      "Epoch 8, Loss: nan\n",
      "Epoch 9, Loss: nan\n",
      "Epoch 10, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(epoch, model, train_loader, loss_fn):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(pred, batch.y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print or log the training loss\n",
    "    print(f\"Epoch {epoch}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Example usage:\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(epoch, model, train_dataset, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb2b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaddf8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce7140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
